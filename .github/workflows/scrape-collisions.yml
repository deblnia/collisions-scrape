name: NYC Collision Data Scraper

on:
  schedule:
    - cron: '0 0 * * *'  # Runs at midnight UTC daily
  workflow_dispatch:      # Allows manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
    - uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas sodapy requests
        
    - name: Scrape data
      run: |
        python -m pip install --upgrade pip
        cat << EOF > scrape.py
        from sodapy import Socrata
        import pandas as pd
        from datetime import datetime, timedelta
        import sys

        try:
            # Initialize Socrata client
            client = Socrata("data.cityofnewyork.us", None)
            
            # Get date range for last 24 hours
            end_date = datetime.now()
            start_date = end_date - timedelta(days=1)
            
            print(f"Fetching data from {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}")
            
            # Fetch data for last 24 hours - using crash_date
            query = f"crash_date >= '{start_date.strftime('%Y-%m-%d')}'"
            print(f"Query: {query}")
            
            results = client.get("h9gi-nx95", 
                               where=query,
                               limit=50000)
            
            print(f"Retrieved {len(results)} records")
            
            if not results:
                print("Warning: No data retrieved!")
                sys.exit(1)
            
            # Convert to pandas DataFrame
            df = pd.DataFrame.from_records(results)
            
            # Basic data validation
            print(f"DataFrame shape: {df.shape}")
            print("\nColumns:")
            print(df.columns.tolist())
            print("\nSample of data:")
            print(df.head())
            
            # Save to CSV
            output_file = f'nyc_collisions_{end_date.strftime("%Y-%m-%d")}.csv'
            df.to_csv(output_file, index=False)
            print(f"\nData saved to {output_file}")
            
        except Exception as e:
            print(f"Error occurred: {str(e)}")
            sys.exit(1)
        EOF
        python scrape.py
        
    - name: Commit and push if changes
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git add *.csv
        git diff --quiet && git diff --staged --quiet || (git commit -m "Update collision data for $(date +'%Y-%m-%d')" && git push)